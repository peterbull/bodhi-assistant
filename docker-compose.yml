services:
  app:
    build:
      context: ./backend
      dockerfile: backend.dockerfile
    env_file:
      - .env
    volumes:
      - ./backend:/app
      - "/app/node_modules" # making sure not to attach to host node_modules
    ports:
      - "3000:3000"
      - "9229:9229"
    command: ["npm", "run", "start"]

  langfuse-server:
    image: ghcr.io/langfuse/langfuse:latest
    depends_on:
      - db
    ports:
      - "3001:3000"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/postgres
      - NEXTAUTH_SECRET=mysecret
      - SALT=mysalt
      - NEXTAUTH_URL=http:localhost:3000
      - TELEMETRY_ENABLED=${TELEMETRY_ENABLED:-true}
      - NEXT_PUBLIC_SIGN_UP_DISABLED=${NEXT_PUBLIC_SIGN_UP_DISABLED:-false}
      - LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-false}
    restart: on-failure

  db:
    image: pgvector/pgvector:pg16
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
    ports:
      - 5432:5432
    volumes:
      - database_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 30s
      retries: 3

  # weaviate:
  #   image: cr.weaviate.io/semitechnologies/weaviate:1.25.4
  #   restart: on-failure:0
  #   volumes:
  #     - ./data:/var/lib/weaviate
  #   ports:
  #     - 8080:8080
  #     - 50051:50051
  #   environment:
  #     QUERY_DEFAULTS_LIMIT: 20
  #     AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
  #     PERSISTENCE_DATA_PATH: "./data"
  #     DEFAULT_VECTORIZER_MODULE: text2vec-transformers
  #     ENABLE_MODULES: text2vec-transformers
  #     TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080
  #     CLUSTER_HOSTNAME: "node1"
  # t2v-transformers:
  #   image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1
  #   environment:
  #     ENABLE_CUDA: 0 # set to 1 to enable
  # NVIDIA_VISIBLE_DEVICES: all # enable if running with CUDA
  # deploy:
  #   resources:
  #     reservations:
  #       devices:
  #         - driver: nvidia
  #           count: all
  #           capabilities: [gpu]

volumes:
  database_data:
    driver: local
  # weaviate_data:
